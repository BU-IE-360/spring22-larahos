---
title: "IE360 Project"
author: "Group 25: Fatih Mecidiye, Lara Hoş, Hatice Serra Hakyemez"
date: "07/06/2022"
output: rmdformats::readthedown
---

# 1. Introduction

  
|        Solar power plants provide a sustainable way to generate energy, however especially with solar energy, it is extremely important to make future predictions for the production values due to storage issues and unavailability of using solar power in certain times during the day. Forecasts of different time horizons for electricity generated by solar power plants are made in order to minimize the risks of solar power trade and energy distribution. Changing weather conditions, climate and geographical characteristics affect solar power plant production. With these in mind, this project aims to analyze the data of and construct a model to make a day-ahead predictions of production values for the KIVANC 2 GES solar power plant located in Mersin (between 36-37° north latitude and 33-35° east longitude). 

|        Data is collected from February 1st 2021 to June 6th 2022 with hourly frequency, it includes productions values and weather values for 9 coordinates nearby the power plant. These weather variables are temperature, relative humidity, downward shortwave radiation flux and percentage total cloud cover data for low-level type of clouds at the provided location. Temperature increase of solar panels results in lower voltage outputs, humidity and shading decreases production and downward shortwave radiation has an effect on the efficiency. Hence, each of the variables should be considered carefully when building the model. For this purpose, time series analysis along with visualizations of the given data will be made, time series regression and autoregressive moving average methods will be used. 

|        Different models are considered and compared with respect to their error values. Finally the "best" model is proposed for forecasting the target value.

First we will start by making necessary arrangements in the data files and check the summary.

```{r message=FALSE,warning=FALSE}
require(rmdformats)
require(data.table)
require(skimr)
require(ggcorrplot)
require(lubridate)
require(forecast)
require(tseries)
require(urca)

production_path <- "/Users/larahos/Downloads/2022-06-06_production_weather/2022-06-06_production.csv"
weather_path <-"/Users/larahos/Downloads/2022-06-06_production_weather/2022-06-06_weather.csv"

prod <- fread(production_path)
long_weather <- fread(weather_path)

prod2 <- copy(prod)

threedays=c("2022-06-05","2022-06-06","2022-06-07")

tmpprod=matrix(0,nrow=72,ncol=3)
tmpprod[,1]=c(rep(threedays[1],24),rep(threedays[2],24),rep(threedays[3],24))
tmpprod[,2]=rep(0:23,3)
tmpprod[,3]=rep(NA,72)
tmpprod=data.table(tmpprod)
setnames(tmpprod,"V1","date")
setnames(tmpprod,"V2","hour")
setnames(tmpprod,"V3","production")
tmpprod[,date:=as.IDate(date)]
tmpprod[,hour:=as.integer(hour)]
tmpprod[,production:=as.double(production)]

prod=rbind(prod,tmpprod)

prod[,dateTime := ymd(date) + dhours(hour)]
prod = prod[order(dateTime)]
head(prod)

```

Our data set involves date and production values for a period of 2 years. Below, some graphics are printed to see which relations to investigate through project and build model on. 

```{r message=FALSE,warning=FALSE}

ggplot(prod,aes(x=dateTime,y=production)) + geom_line() + ggtitle("Hourly Production Values")+xlab("Date")+ylab("Production")

# first week of the given data 
ggplot(prod[date <= "2021-02-08" & date >= "2021-02-01"],aes(x=dateTime,y=production)) + geom_line(color="blue") + ggtitle("Hourly Production Values In The First Week")+xlab("Date")+ylab("Production")

# daily data
daily_series <-  prod[,list(daily_production = mean(production)),by= list(date)]
daily_series=daily_series[!is.na(daily_production)]
ggplot(daily_series,aes(x=date,y=daily_production)) + geom_line(color="red") + ggtitle("Daily Production Values")+xlab("Date")+ylab("Production")

# monthly data
prod$month = month(prod$date)
prod$year = year(prod$date)
monthly_production <-  prod[,list(monthly_production = mean(production)),by= list(month,year)]
monthly_production[,date := as.Date(paste(year,"-",month,"-01",sep=""), format='%Y-%m-%d')]
ggplot(monthly_production,aes(x=date,y=monthly_production)) + geom_line(color="darkgreen") + ggtitle("Monthly Production Values")+xlab("Date")+ylab("Production")
```

|        As it can be seen, output values don't appear to be random over time. Hourly, daily and monthly patterns can be observed from the above plots. Autocorrelation and effect of other variables should also be taken into account. From here, these dependencies will be investigated through the project. 
As for the next steps, the time series will be tried to modeled in the sense of different predictors while trying different models in each step to describe the solar power.  


# 2. Related Literature

|        Due to it's significance, solar power forecasting is a frequently studied subject, hence many different approaches that have been proposed can be found in the literature. For example, [Rafał Rybnik](https://netlabe.com/how-to-predict-solar-energy-production-887ce31ec9d1) starts his forecast attempts by making use of naive forecast and moving average, then moves on to utilizing external variables. At this part, he mentions the consequences of two different approaches using predictors when making future predictions(using historical data of the predictor or also taking into account it's forecasted value). He makes the decision to use the historical data in order to avoid any additional error. Another useful example is the [article](https://www.osti.gov/servlets/purl/1642616) written by Bismark Singh and David Pozo. They focus on using ARMA models to forecast solar power generation. They test several ARMA models to find the best one among them. To use the ARMA model, they check the stationarity of the time series by utilizing the Augmented Dickey-Fuller (ADF) test and mention that using an ARIMA model might be more suitable for a non-stationary series. Consequently, these considerations will be applied in the analysis of time series data. Additionally, the R codes provided by the professor and the assistant of the course, and related time series subjects slides were used in the analysis and calculations in this study.
|        Overall, if machine learning methods are not taken into account, solar power production forecast in the literature frequently makes use of ARIMA, ARMA models and time series regression through weather variables.


# 3. Approach


|        Production data was already modified into a daily series. After seeing the overall pattern, from here on out trend and seasonality components, weather variables and their correlations with the target variable, and also autocorrelated components will be analyzed. 

## 3.1 Trend and Seasonality in Daily Production

```{r message=FALSE,warning=FALSE}
daily_series[,monthFactor := as.factor(format(daily_series$date, "%m"))]
daily_series[,trend := 1: .N]
# model with trend
Model_trend<- lm(daily_production ~ trend, daily_series)
summary(Model_trend)

daily_series[,trend_const := predict(Model_trend,daily_series)]
ggplot(daily_series,aes(x=date)) + geom_line(aes(y=daily_production, color="real")) + geom_line(aes(y=trend_const, color="trend_const")) + ggtitle("Daily Production Values vs. Trend")+xlab("Date")+ylab("Production")


# residuals
ggplot(daily_series,aes(x=date)) + geom_line(aes(y=daily_production - trend_const, color="residual")) + ggtitle("Difference Between Daily Production Values and Trend Constant")+xlab("Date")+ylab("Residual")
checkresiduals(Model_trend$residuals)
```

There is seen an increasing trend, when we compare the same values for January-April for the years 2021 and 2022. Also the increase of the variance can be inspected visually as the time passes by. 
Model constructed with trend component shows that the daily production values are associated with more than just a trend component. By looking at the residual analysis, we can conclude that residuals are clearly not independent and don't have constant variance. Moreover it can be seen that, while winter month production values are well below the trend line, summer months are larger than the trend. This hints a seasonality component affecting the production values. 


```{r message=FALSE,warning=FALSE}
# add seasonality component

Model_trend_seasonality <- lm(daily_production ~ monthFactor + trend, daily_series)
summary(Model_trend_seasonality)

daily_series[,trend_Seasonality := predict(Model_trend_seasonality,daily_series)]
ggplot(daily_series,aes(x=date)) + geom_line(aes(y=daily_production, color="real")) + geom_line(aes(y=trend_Seasonality, color="trend_Seasonality")) + ggtitle("Daily Production Values vs. Trend+Seasonality")+xlab("Date")+ylab("Production")

# residuals
ggplot(daily_series,aes(x=date)) + geom_line(aes(y=daily_production - trend_Seasonality, color="residual2")) +  ggtitle("Difference Between Daily Production Values and Trend+Seasonality Factor")+xlab("Date")+ylab("Production")
checkresiduals(Model_trend_seasonality$residuals)
```
By adding seasonality component, the level of the production values are captured better. 
Adding the seasonality gave a better model, however residuals still don't have constant variance, high values in autocorrelation and not normally distributed. Furthermore, other variables still need to be considered, such as weather values. 


## 3.2 Time Series Analysis

|        At this point it may be a good idea to test if the daily production values are stationary, so that next steps can be taken accordingly.

```{r message=FALSE,warning=FALSE}
adf.test(daily_series$daily_production)
```

|        Augmented Dickey-Fuller is a commonly used statistical test for checking the stationarity property of a time series. Test results show that, since p-value is not significant enough, null hypothesis is not rejected. Hence time series is not concluded to be stationary. Moreover, an ARIMA model rather than ARMA model is more suitable to the data.

```{r message=FALSE,warning=FALSE}
# daily time series
daily_ts <- ts(daily_series$daily_production, start = c(2021,02,01), frequency = 365)
rootTest=ur.kpss(daily_ts) 
summary(rootTest)
```

|        Unit root test helps us to determine whether differencing is needed. It is another measure to examine stationarity. Since test statistic is not small enough, it can be concluded that differencing is required. 


```{r message=FALSE,warning=FALSE}
### time plot
autoplot(daily_ts) +
  ggtitle("Time Series: Daily Production") +
  ylab("Production in given units")

### take the first difference
ddaily_ts <- diff(daily_ts)

### time plot
autoplot(ddaily_ts) +
  ggtitle("Time Series: Change in Daily Production") +
  ylab("Production in given units")


### seasonality investigation
ggseasonplot(ddaily_ts) +
  ggtitle("Season Plot: Change in Daily Production") +
  ylab("Production in given units")


ggseasonplot(ts(monthly_production$monthly_production[1:15], start = c(2021,02), frequency = 12)) +  ggtitle("Season Plot: Monthly Production")+xlab("Date")+ylab("Production")
```


|        Looking at the time series plot of daily production values and change in daily production values over the given time period, it can be inferred that the variability of the data is not constant over time. Especially, the variability is largest around the beginning of year 2022. This should be taken into account while building the model. The variability will tried to be minimized while building a linear regression model.
|        Other than that, comparing the monthly trend of the beginning of years 2021 and 2022, one can say that a similarity is seen. 


```{r message=FALSE,warning=FALSE}
#Time Series Decomposition
acf(daily_ts[1:length(daily_ts)])
pacf(daily_ts[1:length(daily_ts)])
dailyts <- ts(daily_ts, freq=15)

daily_ts_additive<-decompose(dailyts, type="additive")
plot(daily_ts_additive) 

daily_ts_multip<-decompose(dailyts, type="multiplicative")
plot(daily_ts_multip)
```


|        Time series of daily production values are highly autocorrelated. Moreover, judging by the additive and multiplicative decomposition plots of the series, both decompositions' random variable component violates the constant variance assumption. ARIMA or a regression model seems to be most suitable for the given data.
When examined the PACF graph for time series analysis where effects between the lags are extracted, it can be seen that last 3 days have a significant effect on the current day's value. 



## 3.3 External Variables, Correlation and Regression

```{r message=FALSE,warning=FALSE}
# long to wide
wide_weather<- dcast(long_weather, date + hour~ variable + lat + lon , value.var = c("value"))

# daily weather
daily_weather <- dcast(long_weather, date ~ variable + lat + lon, value.var="value", fun.aggregate=mean)

daily_weather[,residual_model2 := c(daily_series$daily_production - daily_series$trend_Seasonality, rep(NA,13))]

correl_info=cor(daily_weather[1:nrow(daily_weather),2:37])

cbind(cor(cbind(data.table(daily_series$daily_production),daily_weather[1:454,2:37]))["V1",])


``` 

Most of the variables have a correlation value around 0.5 depending on the coordinate, however none of them have a high correlation value itself. That's why the mean of locations will be taken into account to build a model and the significance of their effect will be discussed based on the model. 

```{r message=FALSE,warning=FALSE}
temp=wide_weather[date<="2022-06-06"]

rownum=nrow(prod)/24

x1=0
for(i in 1:(rownum*24)){
  x1[i]=mean(as.matrix(temp[i,2:10]))
}
x2=0
for(i in 1:(rownum*24)){
  x2[i]=mean(as.matrix(temp[i,11:19]))
}
x3=0
for(i in 1:(rownum*24)){
  x3[i]=mean(as.matrix(temp[i,20:28]))
}
x4=0
for(i in 1:(rownum*24)){
  x4[i]=mean(as.matrix(temp[i,29:37]))
}

prod[,trend:=1:.N]
prod[,m_sf:=x1]
prod[,m_hum:=x2]
prod[,m_cl:=x3]
prod[,m_tmp:=x4]

library(corrplot)
library(RColorBrewer)
?data.table
cR <- prod[,c(3,8,9,10,11)]
CorrGraph <- as.data.frame(cR)
corr <- cor(CorrGraph, use = "pairwise.complete.obs")

ggcorrplot(corr)

```
As seen in the above figure, humidity level and cloud layers have a stronger correlation with production values more than other variables. So we expect to use these variables in our model, however it will be better to analyze while building the model.

```{r message=FALSE,warning=FALSE}
capacity=matrix(0,nrow=(nrow(prod)/24)-30,24)

for(i in 0:23){
  temp_prod=prod[hour==i]
  for(j in 31:(nrow(prod)/24)){
    capacity[(j-30),(i+1)]<-max(as.matrix(temp_prod[(j-30):j]$production))
  }
}

cap_temp=NULL

for(j in 1:nrow(capacity)){
 cap_temp=c(cap_temp,capacity[j,1:24])   
}

capacity=c(rep(NA,30*24),cap_temp)

prod[,capacity:=capacity]

prod[,lag72:=shift(prod$production, 72L, NA)]

prod[,lagcap72:=shift(prod$capacity, 72L, NA)]

```

At last, capacity values are added to the data set, since for each hour within the month, there is a maximum level that solar panel can produce up-to. Also the lagged value of 3 days both for production and capacity to the data set for modeling purposes, we could not add lag 1-2 since these dates are not provided in the resource. 

## 3.4 Moving Average Method

```{r message=FALSE,warning=FALSE}
daily_series[,ma_week := ma(daily_series$daily_production, order=7)]
ggplot(daily_series,aes(x=date)) +geom_line(aes(y = daily_production, color = "daily_production")) + geom_line(aes(y = ma_week, color = "weekly_ma"))  +  ggtitle("Moving Average Plot of Production Values")+xlab("Date")+ylab("Production")

daily_series[,ma_month := ma(daily_series$daily_production, order=30)]
ggplot(daily_series,aes(x=date)) +geom_line(aes(y = daily_production, color = "daily_production")) + geom_line(aes(y = ma_month, color = "monthly_ma"))  +  ggtitle("Moving Average Plot of Production Values")+xlab("Date")+ylab("Production")
```

|       Weekly and monthly moving average plots give an idea about the general trend of production values. These plots also agree with the non-stationarity assumption of the daily production data. 


# 4. Building Models
## 4.1 Linear Regression Approach

There will be 2 linear models will be built through this section, the first one is a general model, which is irrespective of hours based on a general trend, seasonality, lagged values and external variables. These model is likely to require manual correction since in some hours, the facility is not producing any solar power at all.
The second one will be an hourly model, which is a preferred way to increase predictability of the model and in our case, has a better understanding of the hourly variations as an initial assumption. 
The best model of the first approach will be decided based on R^2 values and AIC.

```{r message=FALSE,warning=FALSE}

fit1=lm(production~as.factor(hour)+as.factor(month)+m_sf+m_hum+m_cl+m_tmp+lag72,prod)
summary(fit1)
AIC(fit1)

fit2=lm(sqrt(production)~as.factor(hour)+as.factor(month)+m_sf+m_hum+m_cl+m_tmp+lag72,prod)
summary(fit2)
AIC(fit2)

fit3=lm(sqrt(production)~as.factor(hour)+as.factor(month)+m_cl+m_tmp+lag72,prod)
summary(fit3)
AIC(fit3)

fit4=lm(sqrt(production)~as.factor(hour)+as.factor(month)+m_cl+m_tmp+sqrt(lag72)+lagcap72,prod)
summary(fit4)
AIC(fit4)

checkresiduals(fit4)

prod[,lm4_pred:=(predict(fit4,prod))^2]
daily_pr<-prod[,list(daily_production = mean(production),daily_prediction = mean(lm4_pred)),by= list(date)]
monthly_pr<-prod[,list(monthly_production = mean(production),monthly_prediction = mean(lm4_pred),
date = as.Date(paste(year,"-",month,"-01",sep=""), format='%Y-%m-%d')),by= list(month,year)]

ggplot(prod,aes(x=date)) +geom_line(aes(y = production, color = "production")) + geom_line(aes(y = (predict(fit4,prod))^2, color = "prediction")) +ggtitle("Hourly Production vs Predicted Values")+xlab("Date")+ylab("Production")

ggplot(daily_pr,aes(x=date)) +geom_line(aes(y = daily_production, color = "daily_production")) + geom_line(aes(y = daily_prediction, color = "daily_prediction")) +ggtitle("Daily Production vs Predicted Values")+xlab("Date")+ylab("Production")

ggplot(monthly_pr,aes(x=date)) +geom_line(aes(y =monthly_production , color = "monthly_production")) + geom_line(aes(y = monthly_prediction, color = "monthly_prediction")) +ggtitle("Monthly Production vs Predicted Values")+xlab("Date")+ylab("Production")


#0,1,2,3,4,5,20,21,22,23 always zero

```

First model is built based on external variables like cloud layer, temperature, lagged values of capacity and production, seasonality and hourly seasonality. It has the lowest value of AIC and sufficient value of R^2 to represent our dataset. 
Square root is used to deal with the increasing variance of the dataset, all predictors look significant so this is the winning model for our first approach of linear models.

## 4.2 Hourly Linear Regression Model

```{r message=FALSE,warning=FALSE}
# identify # of days to forecast
todays_date=as.Date("2022-06-06")
forecast_date=todays_date+1
latest_available_prod_date=as.Date(max(prod2$date))
n_days=as.numeric(forecast_date-latest_available_prod_date)

forecasted_production=tail(prod2,n_days*24)
forecasted_production[,date:=date+n_days]
forecasted_production[,production:=NA]

# actual production data with forecasted dates
production_with_forecast=rbind(prod2,forecasted_production)

mdata <- melt(production_with_forecast, id=c("date","production"))

production_in_hours <- data.table()
info_for_hour1 <- mdata[value == 1]
production_in_hours[,date:=info_for_hour1$date]
hours <- c(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23)
for(i in hours){
  colname = paste("V", i, sep = "")
  colname
  b <- mdata[value == i]
  production_in_hours[,as.character(colname) := b$production]
}


weatherup <- data.table()
weatherup[,date:=production_with_forecast$date]
weatherup[,hour:=production_with_forecast$hour]
weatherup[,m_sf:=x1]
weatherup[,m_hum:=x2]
weatherup[,m_cl:=x3]
weatherup[,m_tmp:=x4]

daily_weather <- weatherup[,list(daily_temp = mean(m_tmp),daily_hum = mean(m_hum),daily_sf = mean(m_sf),daily_cl = mean(m_cl)),by= list(date)]

prod_weather = merge(production_in_hours, daily_weather,by="date")
## example for lm model for hour 8

hour8_prod <- data.table()
hour8_prod[,date:=prod_weather$date]
hour8_prod[,production:=prod_weather$V8]


hour8_prod[,monthFactor := as.factor(format(hour8_prod$date, "%m"))]
hour8_prod[,trend := 1: .N]
# model with trend
Model_trend<- lm(production ~ trend + monthFactor, hour8_prod)
summary(Model_trend)

hour8_prod[,trend_const := predict(Model_trend,hour8_prod)]

ggplot(hour8_prod[25:476],aes(x=date)) +
  geom_line(aes(y=production, color="real")) +
  geom_line(aes(y=trend_const, color="trend_const")) +
  ggtitle("At hour 8 Production Values vs. Trend")+xlab("Date")+ylab("Production")

acf(hour8_prod$production[1:473] - hour8_prod$trend_const[1:473])


hour8_prod[,lag3:=shift(hour8_prod$production, 3L, NA)]
hour8_prod[,ma_2 := ma(hour8_prod$production, order=2)]
hour8_prod$ma_2[483:486] = hour8_prod$ma_2[482]


Model_trend2<- lm(production ~ trend + monthFactor + lag3 +ma_2, hour8_prod)
summary(Model_trend2)
hour8_prod[,lm2 := predict(Model_trend2,hour8_prod)]

ggplot(hour8_prod[25:476],aes(x=date)) +
  geom_line(aes(y=production, color="real")) +
  geom_line(aes(y=lm2, color="trend_const")) +
  ggtitle("At hour 8 Production Values vs. Trend")+xlab("Date")+ylab("Production")


library(corrplot)

correlation_info = cor(prod_weather[,c(2:29)],method = "pearson", use = "pairwise.complete.obs")

ggcorrplot(correlation_info,
           type = "lower",
           lab = TRUE)

## hum_9, m_temp8
hour8_prod[,hum := prod_weather$daily_hum]
#hour8_prod[,m_temp := production_with_weather_in_hours$m_tmp16]
model_with_regressors = lm(production ~ trend + monthFactor + hum + ma_2, hour8_prod)
summary(model_with_regressors)
hour8_prod[,lm_regressors := predict(model_with_regressors,hour8_prod)]

ggplot(hour8_prod[25:476],aes(x=date)) +
  geom_line(aes(y=production, color="real")) +
  geom_line(aes(y=lm_regressors, color="regressors")) +
  ggtitle("At hour 8 Production Values vs. regressors")+xlab("Date")+ylab("Production")
checkresiduals(model_with_regressors)

res <- resid(model_with_regressors)
plot(fitted(model_with_regressors), res)
qqnorm(res)
qqline(res)


hour5_prod <- prod_weather[,c(1,7,26:29)]
hour6_prod <- prod_weather[,c(1,8,26:29)]
hour7_prod <- prod_weather[,c(1,9,26:29)]
hour8_prod <- prod_weather[,c(1,10,26:29)]
hour9_prod <- prod_weather[,c(1,11,26:29)]
hour10_prod <- prod_weather[,c(1,12,26:29)]
hour11_prod <- prod_weather[,c(1,13,26:29)]
hour12_prod <- prod_weather[,c(1,14,26:29)]
hour13_prod <- prod_weather[,c(1,15,26:29)]
hour14_prod <- prod_weather[,c(1,16,26:29)]
hour15_prod <- prod_weather[,c(1,17,26:29)]
hour16_prod <- prod_weather[,c(1,18,26:29)]
hour17_prod <- prod_weather[,c(1,19,26:29)]
hour18_prod <- prod_weather[,c(1,20,26:29)]
hour19_prod <- prod_weather[,c(1,21,26:29)]
hour20_prod <- prod_weather[,c(1,22,26:29)]



dt_list = list(hour5_prod, hour6_prod,hour7_prod,hour8_prod,hour9_prod,hour10_prod,hour11_prod,
               hour12_prod,hour13_prod,hour14_prod,hour15_prod,hour16_prod,hour17_prod,
               hour18_prod,hour19_prod,hour20_prod)

prod[,hourly_prediction := 0.00]
prod[,hourly_prediction := as.numeric(hourly_prediction)]
hourly_models <- list()
t = 5
for (dt in dt_list){
  dt[,production:=dt[,2]]
  dt[,monthFactor := as.factor(format(dt$date, "%m"))]
  dt[,trend := 1: .N]
  dt[,ma_2 := ma(dt$production, order=2)]
  dt[,ma_2 := as.numeric(ma_2)]
  dt$ma_2[483:486] = dt$ma_2[482]
  #print(length(dt$ma_2))
  lm_fit = lm(production ~ trend + monthFactor + daily_hum + dt$ma_2 , dt)
  hourly_models[[t-4]] <- summary(lm_fit)
  dt[,lm_regressors := predict(lm_fit,dt)]
  dt$lm_regressors[dt$lm_regressors < 0.1] = 0
  #print(dt$lm_regressors)
  prod$hourly_prediction[prod$hour == t] = dt$lm_regressors
  #print(t)
  t = t+1 
  
}


for(j in 1:16){
  # print(paste("CheckResidual Result for ",j+4, ".00", sep = "" ))
  checkresiduals(hourly_models[[j]]$residuals)
  # summary(hourly_models[[j]])
  
plotting_res <- data.frame(Residuals = hourly_models[[j]]$residuals,
      Fitted_values = prod$hourly_prediction[prod$hour == j+4][1:482])
  print(ggplot(plotting_res,aes(x = Fitted_values, y = Residuals)) +
    geom_point()+
    ggtitle(paste("CheckResidual Result for ",j+4, ".00", sep = "" ))+
    geom_smooth(method = "lm", se = FALSE)
    )
}

prod[,hourly_res := prod$production - prod$hourly_prediction]

acf(prod$hourly_res,na.action=na.pass)

ggplot(prod[date > "2022-05-01"],aes(x=date)) +
  #geom_line(aes(y=production, color="real")) +
  geom_line(aes(y=hourly_res, color="hourly_prediction")) +
  ggtitle("Production Values vs. hourly_prediction")+xlab("Date")+ylab("Production")

plot(prod$hourly_prediction, prod$hourly_res)


qqnorm(prod$hourly_res)
qqline(prod$hourly_res)


forecasted_production$production = prod$hourly_prediction[11593:11664]
forecasted_production

```


When we compare the hourly model with general linear model, it is obvious that hourly model did better in capturing variations, understanding the behavior of time series, lower pacf values and more randomly scattered residuals by visual inspection. 


## 4.3 ARIMA Approach


```{r}
# fitting data
current_date="2022-06-01" 

forecast_with_arima=function(data,forecast_ahead,target_name='Production',
                              is_seasonal=F,is_stepwise=F,is_trace=T,is_approx=F){
    command_string=sprintf('input_series=data$%s',target_name)
    print(command_string)
    eval(parse(text=command_string))
    fitted=auto.arima(input_series,seasonal=T,
                      trace=T,stepwise=T)
    
    forecasted=forecast(fitted,h=forecast_ahead)
    return(list(forecast=as.numeric(forecasted$mean),model=fitted))
}

forecast_with_arima(prod, 3, 'production', T, F, T, F) 

```

ARIMA models are mainly based on past errors of the target variable by analyzing the lagged values and average values, however, in our case seasonality and non-stationary series exist, so a SARIMA model to improve the automated ARIMA model with seasonal adjustments is preferred. Auto arima is used to choose the model with lowest AIC/BIC and now seasonal components will be built on it. 


```{r}
s_arima <- arima(prod$production, order=c(0,1,3), seasonal=c(0,1,1)) %>%
  residuals() %>% ggtsdisplay()

```
This model has a much higher AIC value and autocorrelated errors, so it will be used to improve the final model but not to predict on the production data mainly. Finally, we will try to include regressors to the ARIMA model to check if any improvement is available.

```{r}
arima_with_reg<- auto.arima(prod[,"production"],
  xreg=as.matrix(prod[,c("m_sf","m_cl","m_tmp", "capacity")]))
arima_with_reg
checkresiduals(arima_with_reg)

```
And in this step, capacity and weather regressors are added to the model along with the errors. Even though it is not the case the models performed the best, it definitely performed better with the inclusion of external variables and it is the most out of ARIMA models in our study.


# 5. Forecasting and Evaluation


```{r message=FALSE,warning=FALSE}

forecast_with_lr=function(fmla, data,forecast_data){
    fitted_lm=lm(as.formula(fmla),data)
    forecasted=predict(fitted_lm,forecast_data)
    return(list(forecast=as.numeric(forecasted),model=fitted_lm))
}

train_start=as.Date('2021-02-01')
test_start=as.Date('2022-06-04')
test_end=as.Date('2022-06-07')

test_dates=seq(test_start,test_end, by='day')
test_dates

for(i in 1:length(test_dates)){

forecast_ahead=3
current_date=test_dates[i]-forecast_ahead
    
past_data=prod[date<=current_date]
forecast_data=prod[date==test_dates[i]]
forecasted=forecast_with_lr(fit4, past_data, forecast_data)
forecast_data[,lm_prediction:=forecasted$forecast^2]

}

forecast_data[,residuals:=production-lm_prediction]

forecast_data$lm_prediction

res <- resid(fit4)
plot(fitted(fit4), res)
qqnorm(res)
qqline(res)

#0,1,2,3,4,21,22,23 always zero
#5-20 mostly zero

```

Here, residuals and quantile-quantile plot for the regressive model built with the general(not separated) values of production, lag, capacity and weather variables is checked. It looks like although mostly there is a good fitting with the actual values; there are still problems with the residuals(not random at some places), and lower and upper ends of the Q-Q plot is not even close to ideal. Since ARIMA models have an extremely higher AIC values when compared to linear models and not good at predicting hourly models, they are not included in the forecasting phase.

## 5.1 Error Comparison


```{r message=FALSE,warning=FALSE}

error_calc=function(actual,forecast){
  n=length(actual)
  error=actual-forecast
  mean=mean(actual)
  sd=sd(actual)
  CV=sd/mean
  FBias=sum(error)/sum(actual)
  RMSE=sqrt(sum(error^2)/n)
  MAD=sum(abs(error))/n
  MADP=sum(abs(error))/sum(abs(actual))
  WMAPE=MAD/mean
  df=data.frame(n,mean,sd,CV,FBias,RMSE,MAD,MADP,WMAPE)
  return(df)
}

result_hourly_pred <- error_calc(prod[date > ymd(20220201) & date < ymd(20220521)]$production, prod[date > ymd(20220201) & date < ymd(20220521)]$hourly_prediction)

result_lm4 <- error_calc(prod[date > ymd(20220307) & date < ymd(20220521)]$production, prod[date > ymd(20220307) & date < ymd(20220521)]$lm4_pred)


result_hourly_pred
result_lm4

```


Comparing the error values of the models, and considering our previous observations, it seems almost obvious that separately built model(for each hour) is a better choice for usage.


# 6. Results

|        After making observations about the residuals and comparing the error values of the models we built, it seems that the best model to use for our forecasts of solar production is the model made by separating each hour's production values and building a separate model for each. This model gives better error values overall and is closer with less bias from the actual values when comparing with the other models. 


# 7. Conclusions and Future Work

|        In this study, after the visualization and investigating the properties of the time series of the provided data of solar power production values, statistical analysis methods such as time series analysis, arima, time series regression were used in order to build a model for prediction of future production values. Moreover, it seemed that separately building regressive models for each hour of production was useful, therefore later on it was also considered. In the competition phase, predictions calculated by general model built from using weather variables and lagged values was used, and for some hours, forecasted values were ignored and using general observations from the data, 0 values or full capacity production values are entered instead.  After comparing the general model adequacy, residual analysis and overall error of models, best one is chosen to be used in future predictions. And thus the analysis for this study is concluded.

|        For future analysis, it might be beneficial to look into government regulations concerning solar production capacity, affects of special days and specific economic events influencing energy production and look for or create dummy variables concerning these affects, then add them to create a better model.  

# 8. Code

Rmd codes are [here](https://BU-IE-360.github.io/spring22-HaticeSerraHakyemez/IE360Project/RMDFile.Rmd)





